<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title><code>rrr</code> for Multivariate Analysis &bull; rrr</title><!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous"><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">rrr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="http://github.com/chrisaddy/rrr">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1><code>rrr</code> for Multivariate Analysis</h1>
                        <h4 class="author">Chris Addy</h4>
            
            <h4 class="date">2016-11-10</h4>
          </div>

    
    
<div class="contents">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools::<span class="kw">install_github</span>(<span class="st">"chrisaddy/rrr"</span>)
<span class="kw">library</span>(rrr)</code></pre></div>
<div id="reduced-rank-regression-and-its-special-cases" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#reduced-rank-regression-and-its-special-cases" class="anchor"> </a></body></html>Reduced-Rank Regression and Its Special Cases</h3>
<p>The multivariate linear regression model is given by</p>
<p><span class="math display">\[
\overset{s \times 1}{\mathbf{Y}} = \overset{s \times 1}{\boldsymbol{\mu}} + \overset{s \times r}{\mathbf{C}} \; \overset{r \times 1}{\mathbf{X}} + \overset{s \times 1}{\varepsilon}
\]</span></p>
<p>with</p>
<p><span class="math display">\[
\mathrm{E}\left(\varepsilon\right) = \mathbf{0}, \quad \mathrm{cov}\left(\varepsilon\right) = \mathbf{\Sigma}_{\varepsilon \varepsilon}
\]</span></p>
<p>and <span class="math inline">\(\varepsilon\)</span> is distributed independently of <span class="math inline">\(\mathbf{X}.\)</span></p>
<p>We introduce the possibility that <span class="math inline">\(\mathbf{C}\)</span> is rank-deficient, i.e.,</p>
<p><span class="math display">\[
\mathrm{rank}\left(\mathbf{C}\right) = t \quad \mathrm{min}\left(r, s \right)
\]</span></p>
<p>When <span class="math inline">\(t = s\)</span>, the regression model is <em>full-rank</em>, and can be fit using multiple regression on each <span class="math inline">\(Y_i \in \mathbf{Y}.\)</span> When <span class="math inline">\(t &lt; s\)</span>, <span class="math inline">\(\mathbf{C}\)</span> can be decomposed into non-unique matrices <span class="math inline">\(\mathbf{A}_{s \times t}\)</span> and <span class="math inline">\(\mathbf{B}_{t \times r}\)</span>, such that <span class="math inline">\(\mathbf{C} = \mathbf{AB},\)</span> and the multivariate regression model is given by</p>
<p><span class="math display">\[
\overset{s \times 1}{\mathbf{Y}} = \overset{s \times 1}{\boldsymbol{\mu}} + \overset{s \times t}{\mathbf{A}} \; \overset{t \times r}{\mathbf{B}} \; \overset{r \times 1}{\mathbf{X}} + \overset{s \times 1}{\varepsilon}
\]</span></p>
<p>Finding <span class="math inline">\(\mathbf{A}, \mathbf{B}\)</span>, and ultimately the <em>reduced-rank regression coefficient</em> <span class="math inline">\(\mathbf{C}^{\left(t\right)}\)</span>, is done by minimizing the weighted sum-of-squares criterion</p>
<p><span class="math display">\[
\mathrm{E}\left[\left(\mathbf{Y} - \boldsymbol{\mu} - \mathbf{ABX}\right)^\tau \mathbf{\Gamma}\left(\mathbf{Y} - \boldsymbol{\mu} - \mathbf{ABX}\right)\right]
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\Gamma}\)</span> is a positive-definite symmetric <span class="math inline">\(\left(s \times s\right)\)</span>-matrix of weights, the expectation of which is taken over the joint distribution <span class="math inline">\(\left(\mathbf{X}^\tau, \mathbf{Y}^\tau\right)^\tau\)</span>. This weighted sum-of-squares criterion is minimized when</p>
<p><span class="math display">\[
\begin{aligned}
    \boldsymbol{\mu}^\left(t\right) &amp; = \boldsymbol{\mu}_Y - \mathbf{A}^{\left(t\right)}\mathbf{B}^{\left(t\right)}\boldsymbol{\mu}_X \\
    \mathbf{A}^{\left(t\right)} &amp; = \mathbf{\Gamma}^{-1/2}\mathbf{V}_t \\
    \mathbf{B}^{\left(t\right)} &amp; = \mathbf{V}_t^\tau \boldsymbol{\Gamma}^{-1/2}\mathbf{\Sigma}_{YX}\mathbf{XX}^{-1} \\
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{V}_t = \left(\mathbf{v}_1, \dots, \mathbf{v}_t\right)\)</span> is an <span class="math inline">\(\left(s \times t\right)\)</span>-matrix, with <span class="math inline">\(\mathbf{v}_j\)</span> the eigenvector associated with the <span class="math inline">\(j\)</span>th largest eigenvalue of</p>
<p><span class="math display">\[
\mathbf{\Gamma}^{1/2}\mathbf{\Sigma}_{YX} \mathbf{\Sigma}_{XX}^{-1} \mathbf{\Sigma}_{XY} \mathbf{\Gamma}^{1/2}
\]</span></p>
<p>Using different values of <span class="math inline">\(\mathbf{\Gamma}\)</span> we can use the reduced-rank regression model carry out classical multivariate procedures.</p>
</div>
<div id="principal-components-analysis" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#principal-components-analysis" class="anchor"> </a></body></html>Principal Components Analysis</h2>
<p>Set</p>
<p><span class="math display">\[
\begin{aligned}
    \mathbf{Y} &amp; \equiv \mathbf{X} \\
    s &amp; = r \\
    \mathbf{\Gamma} &amp; = \mathbf{I}_r \\
\end{aligned}
\]</span></p>
<p>Then, the least-squares error criterion</p>
<p><span class="math display">\[
    \mathrm{E}\left[\left(\mathbf{X} - \boldsymbol{\mu} - \mathbf{A}\mathbf{B}\mathbf{X}\right)^\tau\left(\mathbf{X} - \boldsymbol{\mu} - \mathbf{A}\mathbf{B}\mathbf{X}\right)\right]
\]</span></p>
<p>is minimized by the reduced-rank regression solution,</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \mathbf{A}^{\left(t\right)} &amp; = \left(\mathbf{v}_1, \dots, \mathbf{v}_t\right) \\
        \mathbf{B}^{\left(t\right)} &amp; = \mathbf{A}^{\left(t\right) \tau} \\
        \boldsymbol{\mu}^{\left(t\right)} &amp; = \left(\mathbf{I}_r - \mathbf{A}^{\left(t\right)}\mathbf{B}^{\left(t\right)}\right)\boldsymbol{\mu}_X \\
    \end{aligned}
\end{equation}\]</span>
<p>where <span class="math inline">\(\mathbf{v}_j = \mathbf{v}_j \left(\mathbf{\Sigma}_{XX}\right)\)</span> is eigenvector associated with the <span class="math inline">\(j\)</span>th largest eigenvalue of <span class="math inline">\(\mathbf{\Sigma}_{XX}.\)</span></p>
<p>The best reduced-rank approximation to the original <span class="math inline">\(\mathbf{X}\)</span> is</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \hat{\mathbf{X}}^{\left(t\right)} &amp; =
        \boldsymbol{\mu}^{\left(t\right)} + \mathbf{A}^{\left(t\right)}\mathbf{B}^{\left(t\right)} \mathbf{X}
    \end{aligned}
\end{equation}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(readr)
digits &lt;-<span class="st"> </span><span class="kw">read_delim</span>(<span class="st">"http://astro.ocis.temple.edu/~alan/pendigits.txt"</span>, <span class="dt">delim =</span> <span class="st">" "</span>, <span class="dt">col_names =</span> <span class="ot">FALSE</span>)

digits_class &lt;-<span class="st"> </span>digits %&gt;%<span class="st"> </span>dplyr::<span class="kw">select</span>(X35)
digits_features &lt;-<span class="st"> </span>digits %&gt;%<span class="st"> </span>dplyr::<span class="kw">select</span>(-X35, -X36)

<span class="co">#digits_pca &lt;- rrpca(digits_features)</span>

<span class="co">#pca_gof(digits_features) %&gt;% round(4)</span>

<span class="co">#pca_rank_trace(digits_features)</span>

<span class="co">#pca_rank_trace_plot(digits_features)</span>

<span class="co">#pc_pairwise_plot(digits_features, class_labels = digits_class)</span>

<span class="co">#pc_plot_3D(digits_features, class_labels = digits_class)</span></code></pre></div>
</div>
<div id="canonical-variate-analysis" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#canonical-variate-analysis" class="anchor"> </a></body></html>Canonical Variate Analysis</h2>
<p><span class="math inline">\(\mathbf{X}, \mathbf{Y}\)</span> are jointly distributed, with</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \mathrm{E}\left\{
        \begin{pmatrix}
            \mathbf{X} \\
            \mathbf{Y} \\
        \end{pmatrix}
        \right\} =
        \begin{pmatrix}
            \boldsymbol{\mu}_X \\
            \boldsymbol{\mu}_Y \\
        \end{pmatrix}, \quad
        \mathrm{cov}\left\{
        \begin{pmatrix}
            \mathbf{X} \\
            \mathbf{Y} \\
        \end{pmatrix}\right\} =
        \begin{pmatrix}
            \mathbf{\Sigma}_{XX} &amp; \mathbf{\Sigma}_{XY} \\
            \mathbf{\Sigma}_{YX} &amp; \mathbf{\Sigma}_{YY} \\
        \end{pmatrix}
    \end{aligned}
\end{equation}\]</span>
<p>Let <span class="math inline">\(1 \leq t \leq \mathrm{min}\left(r, s\right)\)</span>. <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Y}\)</span> are linearly projected into new vector variates,</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \boldsymbol{\xi}_{t \times 1} = \mathbf{G}_{t \times r} \mathbf{X}_{r \times 1}, \quad \boldsymbol{\omega}_{t \times 1} = \mathbf{H}_{t \times s} \mathbf{X}_{s \times 1}
        \end{aligned}
        \end{equation}\]</span>
<p>Finding a solution to the problem</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \boldsymbol{\xi} \approx \boldsymbol{\nu} + \boldsymbol{\omega}
    \end{aligned}
\end{equation}\]</span>
<p>requires minimizing the least-squares criterion</p>
<p><span class="math display">\[
    \begin{aligned}
        \mathrm{E}\left[\left(\mathbf{H}\mathbf{Y} - \boldsymbol{\nu} - \mathbf{G}\mathbf{X}\right)\left(\mathbf{H}\mathbf{Y} - \boldsymbol{\nu} - \mathbf{G}\mathbf{X}\right)^\tau\right]
    \end{aligned},
\]</span></p>
<p>where we assume <span class="math inline">\(\mathrm{cov}\left(\boldsymbol{\omega}\right) = \mathbf{I}_t\)</span>. This least-squares criterion is minimized when</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \boldsymbol{\nu}^{\left(t\right)} &amp; = \mathbf{H}^{\left(t\right)} \boldsymbol{\mu}_Y - \mathbf{G}^{\left(t\right)}\boldsymbol{\mu}_Y \\
        \mathbf{G}^{\left(t\right)} &amp; =
        \begin{pmatrix}
            \mathbf{v}_1^\tau \\
            \vdots \\
            \mathbf{v}_t^\tau \\
        \end{pmatrix}
        \mathbf{\Sigma}_{YY}^{-1/2} \mathbf{\Sigma}_{YX}\mathbf{\Sigma}_{XX}^{-1} \\
        \mathbf{H}^{\left(t\right)} &amp; =
        \begin{pmatrix}
            \mathbf{v}_1^\tau \\
            \vdots \\
            \mathbf{v}_t^\tau \\
        \end{pmatrix}
        \mathbf{\Sigma}_{YY}^{-1/2} \\
    \end{aligned}
\end{equation}\]</span>
<p>where <span class="math inline">\(\mathbf{v}_j\)</span> is the eigenvector associated with the <span class="math inline">\(j\)</span>th largest eigenvalue of</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \mathbf{R} &amp; = \mathbf{\Sigma}_{YY}^{-1/2}\mathbf{\Sigma}_{YX} \mathbf{\Sigma}_{XX}^{-1} \mathbf{\Sigma}_{XY} \mathbf{\Sigma}_{YY}^{-1/2}
    \end{aligned}
\end{equation}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### COMBO-17 galaxy data
<span class="kw">data</span>(COMBO17)
galaxy &lt;-<span class="st"> </span><span class="kw">as_data_frame</span>(COMBO17) %&gt;%
<span class="st">       </span><span class="kw">select</span>(-<span class="kw">starts_with</span>(<span class="st">"e."</span>), -Nr, -UFS:-IFD) %&gt;%
<span class="st">       </span><span class="kw">na.omit</span>()

galaxy_x &lt;-<span class="st"> </span>galaxy %&gt;%<span class="st"> </span><span class="kw">select</span>(-Rmag:-chi2red)
galaxy_y &lt;-<span class="st"> </span>galaxy %&gt;%<span class="st"> </span><span class="kw">select</span>(Rmag:chi2red)

<span class="co">#galaxy_x</span>
<span class="co">#galaxy_y</span>

<span class="kw"><a href="../reference/rrcva.html">rrcva</a></span>(galaxy_x, galaxy_y, <span class="dt">rank =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>## $mean
##            [,1]
## [1,] 26.9647035
## [2,]  0.7778445
## [3,] 25.8103529
## [4,] -0.7838949
## [5,] -0.7059124
## [6,]  2.1087757
## 
## $A
##             [,1]       [,2]
## [1,] 0.450509577 -0.3121809
## [2,] 0.071013907 -0.4289359
## [3,] 0.335325320  0.2488848
## [4,] 0.020673543  1.2603829
## [5,] 0.025943827  1.2558874
## [6,] 0.003141958 -0.7126123
## 
## $B
##          UjMAG       BjMAG       VjMAG      usMAG     gsMAG     rsMAG
## [1,] 12.801398 0.030027684 -10.0136034  7.3781810 3.6563154 7.4920875
## [2,] -3.526777 0.007037918  -0.6006888 -0.1396253 0.1362222 0.4440037
##           UbMAG       BbMAG       VnMAG     S280MAG     W420FE     W462FE
## [1,] -20.863684 -0.09214493 -0.28762197 0.114366840 -80.577920 -45.925360
## [2,]   3.573287 -0.01097271  0.01701159 0.004312253  -3.552204  -2.571896
##         W485FD    W518FE   W571FS   W604FE    W646FD      W696FE
## [1,] 12.502665 53.802839 36.09168 3.096505 -8.390231 -42.9136538
## [2,]  4.118007  1.729646  1.42660 2.451877 -3.999906  -0.8652682
##          W753FE    W815FS      W856FD    W914FD    W914FE
## [1,] 34.1142186 -36.60718 -13.4812757 19.003834 2.4553493
## [2,]  0.8532394  -3.14504  -0.2666507  1.330534 0.7642494
## 
## $C
##          UjMAG         BjMAG      VjMAG       usMAG       gsMAG      rsMAG
## [1,]  6.868145  0.0113306551 -4.3237007  3.36752953  1.60467915  3.2366477
## [2,]  2.421839 -0.0008864329 -0.4534481  0.58384375  0.20121867  0.3415933
## [3,]  3.414872  0.0118206732 -3.5073170  2.43934030  1.25995876  2.6227924
## [4,] -4.180439  0.0094912505 -0.9641145 -0.02344814  0.24728106  0.7145027
## [5,] -4.097117  0.0096178660 -1.0141886  0.01606466  0.26593850  0.7519921
## [6,]  2.553446 -0.0049209614  0.3965959  0.12268060 -0.08558559 -0.2928627
##           UbMAG        BbMAG       VnMAG      S280MAG     W420FE
## [1,] -10.514802 -0.038086701 -0.13488715  0.050177153 -35.192194
## [2,]  -3.014323 -0.001836983 -0.02772204  0.006271956  -4.198485
## [3,]  -6.106785 -0.033629466 -0.09221300  0.039423351 -27.903906
## [4,]   4.072383 -0.015734776  0.01549496  0.007799458  -6.142968
## [5,]   3.946362 -0.016171078  0.01390263  0.008382818  -6.551668
## [6,]  -2.611921  0.007529771 -0.01302637 -0.002713629   2.278172
##          W462FE    W485FD    W518FE     W571FS     W604FE    W646FD
## [1,] -19.886918  4.347007 23.698732 15.8142894  0.6295759 -2.531185
## [2,]  -2.158161 -0.878498  3.078842  1.9510913 -0.8318030  1.119880
## [3,] -16.040042  5.217369 18.471937 12.4575124  1.6485712 -3.808972
## [4,]  -4.191013  5.448740  3.292312  2.5442046  3.1543190 -5.214869
## [5,]  -4.421491  5.496120  3.568092  2.7280047  3.1596161 -5.241106
## [6,]   1.688469 -2.895259 -1.063521 -0.9032139 -1.7375083  2.824020
##           W696FE     W753FE     W815FS     W856FD     W914FD     W914FE
## [1,] -19.0628918 15.1024171 -15.510064 -5.9902006  8.1460418  0.8675743
## [2,]  -2.6763216  2.0565989  -1.250598 -0.8429820  0.7788227 -0.1534501
## [3,] -14.6053868 11.6517195 -13.058067 -4.5869784  6.7036162  1.0135508
## [4,]  -1.9777464  1.7806701  -4.720755 -0.6147877  2.0698587  1.0140077
## [5,]  -2.2000238  1.9566260  -4.899547 -0.6846392  2.1640329  1.0235124
## [6,]   0.4817678 -0.5008435   2.126176  0.1476610 -0.8884456 -0.5368989
## 
## $H
##             [,1]       [,2]       [,3]       [,4]      [,5]         [,6]
## [1,]  1.39453594  0.2106292 1.04963650 0.09485012 0.1111437 -0.007471155
## [2,] -0.06686816 -0.1051414 0.07012137 0.31449831 0.3135059 -0.177456306</code></pre>
</div>
<div id="linear-discriminant-analysis" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#linear-discriminant-analysis" class="anchor"> </a></body></html>Linear Discriminant Analysis</h2>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2>Contents</h2>
      <ul class="nav nav-pills nav-stacked"><li><a href="#principal-components-analysis">Principal Components Analysis</a></li>
      <li><a href="#canonical-variate-analysis">Canonical Variate Analysis</a></li>
      <li><a href="#linear-discriminant-analysis">Linear Discriminant Analysis</a></li>
      </ul></div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Chris Addy.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer></div>

  </body></html>
