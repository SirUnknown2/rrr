<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title><code>rrr</code> for Multivariate Analysis &bull; rrr</title><!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous"><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">rrr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="http://github.com/chrisaddy/rrr">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1><code>rrr</code> for Multivariate Analysis</h1>
                        <h4 class="author">Chris Addy</h4>
            
            <h4 class="date">2016-11-08</h4>
          </div>

    
    
<div class="contents">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools::<span class="kw">install_github</span>(<span class="st">"chrisaddy/rrr"</span>)
<span class="kw">library</span>(rrr)</code></pre></div>
<div id="reduced-rank-regression-and-its-special-cases" class="section level3">
<h3 class="hasAnchor"><html><body><a href="#reduced-rank-regression-and-its-special-cases" class="anchor"> </a></body></html>Reduced-Rank Regression and Its Special Cases</h3>
<p>The multivariate linear regression model is given by</p>
<p><span class="math display">\[
\overset{s \times 1}{\mathbf{Y}} = \overset{s \times 1}{\boldsymbol{\mu}} + \overset{s \times r}{\mathbf{C}} \; \overset{r \times 1}{\mathbf{X}} + \overset{s \times 1}{\varepsilon}
\]</span></p>
<p>with</p>
<p><span class="math display">\[
\mathrm{E}\left(\varepsilon\right) = \mathbf{0}, \quad \mathrm{cov}\left(\varepsilon\right) = \mathbf{\Sigma}_{\varepsilon \varepsilon}
\]</span></p>
<p>and <span class="math inline">\(\varepsilon\)</span> is distributed independently of <span class="math inline">\(\mathbf{X}.\)</span></p>
<p>We introduce the possibility that <span class="math inline">\(\mathbf{C}\)</span> is rank-deficient, i.e.,</p>
<p><span class="math display">\[
\mathrm{rank}\left(\mathbf{C}\right) = t \quad \mathrm{min}\left(r, s \right)
\]</span></p>
<p>When <span class="math inline">\(t = s\)</span>, the regression model is <em>full-rank</em>, and can be fit using multiple regression on each <span class="math inline">\(Y_i \in \mathbf{Y}.\)</span> When <span class="math inline">\(t &lt; s\)</span>, <span class="math inline">\(\mathbf{C}\)</span> can be decomposed into non-unique matrices <span class="math inline">\(\mathbf{A}_{s \times t}\)</span> and <span class="math inline">\(\mathbf{B}_{t \times r}\)</span>, such that <span class="math inline">\(\mathbf{C} = \mathbf{AB},\)</span> and the multivariate regression model is given by</p>
<p><span class="math display">\[
\overset{s \times 1}{\mathbf{Y}} = \overset{s \times 1}{\boldsymbol{\mu}} + \overset{s \times t}{\mathbf{A}} \; \overset{t \times r}{\mathbf{B}} \; \overset{r \times 1}{\mathbf{X}} + \overset{s \times 1}{\varepsilon}
\]</span></p>
<p>Finding <span class="math inline">\(\mathbf{A}, \mathbf{B}\)</span>, and ultimately the <em>reduced-rank regression coefficient</em> <span class="math inline">\(\mathbf{C}^{\left(t\right)}\)</span>, is done by minimizing the weighted sum-of-squares criterion</p>
<p><span class="math display">\[
\mathrm{E}\left[\left(\mathbf{Y} - \boldsymbol{\mu} - \mathbf{ABX}\right)^\tau \mathbf{\Gamma}\left(\mathbf{Y} - \boldsymbol{\mu} - \mathbf{ABX}\right)\right]
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\Gamma}\)</span> is a positive-definite symmetric <span class="math inline">\(\left(s \times s\right)\)</span>-matrix of weights, the expectation of which is taken over the joint distribution <span class="math inline">\(\left(\mathbf{X}^\tau, \mathbf{Y}^\tau\right)^\tau\)</span>. This weighted sum-of-squares criterion is minimized when</p>
<p><span class="math display">\[
\begin{aligned}
    \boldsymbol{\mu}^\left(t\right) &amp; = \boldsymbol{\mu}_Y - \mathbf{A}^{\left(t\right)}\mathbf{B}^{\left(t\right)}\boldsymbol{\mu}_X \\
    \mathbf{A}^{\left(t\right)} &amp; = \mathbf{\Gamma}^{-1/2}\mathbf{V}_t \\
    \mathbf{B}^{\left(t\right)} &amp; = \mathbf{V}_t^\tau \boldsymbol{\Gamma}^{-1/2}\mathbf{\Sigma}_{YX}\mathbf{XX}^{-1} \\
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{V}_t = \left(\mathbf{v}_1, \dots, \mathbf{v}_t\right)\)</span> is an <span class="math inline">\(\left(s \times t\right)\)</span>-matrix, with <span class="math inline">\(\mathbf{v}_j\)</span> the eigenvector associated with the <span class="math inline">\(j\)</span>th largest eigenvalue of</p>
<p><span class="math display">\[
\mathbf{\Gamma}^{1/2} \mathbf{\Sigma}_{YX} \mathbf_{XX}^{-1} \mathbf_{XY} \mathbf{\Gamma}^{1/2}
\]</span></p>
<p>Using different values of <span class="math inline">\(\mathbf{\Gamma}\)</span> we can use the reduced-rank regression model carry out classical multivariate procedures.</p>
</div>
<div id="principal-components-analysis" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#principal-components-analysis" class="anchor"> </a></body></html>Principal Components Analysis</h2>
<p>Set</p>
<p><span class="math display">\[
\begin{aligned}
    \mathbf{Y} &amp; \equiv \mathbf{X} \\
    s &amp; = r \\
    \mathbf{\Gamma} &amp; = \mathbf{I}_r \\
\end{aligned}
\]</span></p>
<p>Then, the least-squares error criterion</p>
<p><span class="math display">\[
    \mathrm{E}\left[\left(\mathbf{X} - \boldsymbol{\mu} - \mathbf{A}\mathbf{B}\mathbf{X}\right)^\tau\left(\mathbf{X} - \boldsymbol{\mu} - \mathbf{A}\mathbf{B}\mathbf{X}\right)\right]
\]</span></p>
<p>is minimized by the reduced-rank regression solution,</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \mathbf{A}^{\left(t\right)} &amp; = \left(\mathbf{v}_1, \dots, \mathbf{v}_t\right) \\
        \mathbf{B}^{\left(t\right)} &amp; = \mathbf{A}^{\left(t\right) \tau} \\
        \boldsymbol{\mu}^{\left(t\right)} &amp; = \left(\mathbf{I}_r - \mathbf{A}^{\left(t\right)}\mathbf{B}^{\left(t\right)}\right)\boldsymbol{\mu}_X \\
    \end{aligned}
\end{equation}\]</span>
<p>where <span class="math inline">\(\mathbf{v}_j = \mathbf{v}_j \left(\mathbf{\Sigma}_{XX}\right)\)</span> is eigenvector associated with the <span class="math inline">\(j\)</span>th largest eigenvalue of <span class="math inline">\(\mathbf{\Sigma}_{XX}.\)</span></p>
<p>The best reduced-rank approximation to the original <span class="math inline">\(\mathbf{X}\)</span> is</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \hat{\mathbf{X}}^{\left(t\right)} &amp; =
        \boldsymbol{\mu}^{\left(t\right)} + \mathbf{A}^{\left(t\right)}\mathbf{B}^{\left(t\right)} \mathbf{X}
    \end{aligned}
\end{equation}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(readr)
digits &lt;-<span class="st"> </span><span class="kw">read_delim</span>(<span class="st">"http://astro.ocis.temple.edu/~alan/pendigits.txt"</span>, <span class="dt">delim =</span> <span class="st">" "</span>, <span class="dt">col_names =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   .default = col_integer()
## )</code></pre>
<pre><code>## See spec(...) for full column specifications.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">digits_class &lt;-<span class="st"> </span>digits %&gt;%<span class="st"> </span>dplyr::<span class="kw">select</span>(X35)
digits_features &lt;-<span class="st"> </span>digits %&gt;%<span class="st"> </span>dplyr::<span class="kw">select</span>(-X35, -X36)

digits_class</code></pre></div>
<pre><code>## # A tibble: 10,992 &times; 1
##      X35
##    &lt;int&gt;
## 1      8
## 2      2
## 3      1
## 4      4
## 5      1
## 6      6
## 7      4
## 8      0
## 9      5
## 10     0
## # ... with 10,982 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">digits_features</code></pre></div>
<pre><code>## # A tibble: 10,992 &times; 34
##       X1    X2    X3    X4    X5    X6    X7    X8    X9   X10   X11   X12
##    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;
## 1     47   100    27    81    57    37    26     0     0    23    56    53
## 2      0    89    27   100    42    75    29    45    15    15    37     0
## 3      0    57    31    68    72    90   100   100    76    75    50    51
## 4      0   100     7    92     5    68    19    45    86    34   100    45
## 5      0    67    49    83   100   100    81    80    60    60    40    40
## 6    100   100    88    99    49    74    17    47     0    16    37     0
## 7      0   100     3    72    26    35    85    35   100    71    73    97
## 8      0    39     2    62    11     5    63     0   100    43    89    99
## 9     13    89    12    50    72    38    56     0     4    17     0    61
## 10    57   100    22    72     0    31    25     0    75    13   100    50
## # ... with 10,982 more rows, and 22 more variables: X13 &lt;int&gt;, X14 &lt;int&gt;,
## #   X15 &lt;int&gt;, X16 &lt;int&gt;, X17 &lt;int&gt;, X18 &lt;int&gt;, X19 &lt;int&gt;, X20 &lt;int&gt;,
## #   X21 &lt;int&gt;, X22 &lt;int&gt;, X23 &lt;int&gt;, X24 &lt;int&gt;, X25 &lt;int&gt;, X26 &lt;int&gt;,
## #   X27 &lt;int&gt;, X28 &lt;int&gt;, X29 &lt;int&gt;, X30 &lt;int&gt;, X31 &lt;int&gt;, X32 &lt;int&gt;,
## #   X33 &lt;int&gt;, X34 &lt;int&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">digits_pca &lt;-<span class="st"> </span><span class="kw"><a href="../reference/rrpca.html">rrpca</a></span>(digits_features)

<span class="kw"><a href="../reference/pca_gof.html">pca_gof</a></span>(digits_features) %&gt;%<span class="st"> </span><span class="kw">round</span>(<span class="dv">4</span>)</code></pre></div>
<pre><code>##  [1] 0.7169 0.4681 0.3145 0.2243 0.1664 0.1181 0.0874 0.0607 0.0414 0.0276
## [11] 0.0190 0.0122 0.0078 0.0038 0.0020 0.0003 0.0001 0.0000 0.0000 0.0000
## [21] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000
## [31] 0.0000 0.0000 0.0000 0.0000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#pca_rank_trace(digits_features)</span>

<span class="co">#pca_rank_trace_plot(digits_features)</span>

<span class="co">#pc_pairwise_plot(digits_features, class_labels = digits_class)</span>

<span class="co">#pc_plot_3D(digits_features, class_labels = digits_class)</span></code></pre></div>
</div>
<div id="canonical-variate-analysis" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#canonical-variate-analysis" class="anchor"> </a></body></html>Canonical Variate Analysis</h2>
<p><span class="math inline">\(\mathbf{X}, \mathbf{Y}\)</span> are jointly distributed, with</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \mathrm{E}\left\{
        \begin{pmatrix}
            \mathbf{X} \\
            \mathbf{Y} \\
        \end{pmatrix}
        \right\} =
        \begin{pmatrix}
            \boldsymbol{\mu}_X \\
            \boldsymbol{\mu}_Y \\
        \end{pmatrix}, \quad
        \mathrm{cov}\left\{
        \begin{pmatrix}
            \mathbf{X} \\
            \mathbf{Y} \\
        \end{pmatrix}\right\} =
        \begin{pmatrix}
            \mathbf{\Sigma}_{XX} &amp; \mathbf{\Sigma}_{XY} \\
            \mathbf{\Sigma}_{YX} &amp; \mathbf{\Sigma}_{YY} \\
        \end{pmatrix}
    \end{aligned}
\end{equation}\]</span>
<p>Let <span class="math inline">\(1 \leq t \leq \mathrm{min}\left(r, s\right)\)</span>. <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Y}\)</span> are linearly projected into new vector variates,</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \boldsymbol{\xi}_{t \times 1} = \mathbf{G}_{t \times r} \mathbf{X}_{r \times 1}, \quad \boldsymbol{\omega}_{t \times 1} = \mathbf{H}_{t \times s} \mathbf{X}_{s \times 1}
        \end{aligned}
        \end{equation}\]</span>
<p>Finding a solution to the problem</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \boldsymbol{\xi} \approx \boldsymbol{\nu} + \boldsymbol{\omega}
    \end{aligned}
\end{equation}\]</span>
<p>requires minimizing the least-squares criterion</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \mathrm{E}\left[\left(\mathbf{H}\mathbf{Y} - \boldsymbol{\nu} - \mathbf{G}\mathbf{X}\right)\left(\mathbf{H}\mathbf{Y} - \boldsymbol{\nu} - \mathbf{G}\mathbf{X}\right)^\tau\right]
    \end{aligned},

where we assume $\mathrm{cov}\left(\boldsymbol{\omega}\right) = \mathbf{I}_t$.
\end{equation}\]</span>
<p>. This least-squares criterion is minimized when</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \boldsymbol{\nu}^{\left(t\right)} &amp; = \mathbf{H}^{\left(t\right)} \boldsymbol{\mu}_Y - \mathbf{G}^{\left(t\right)}\boldsymbol{\mu}_Y \\
        \mathbf{G}^{\left(t\right)} &amp; =
        \begin{pmatrix}
            \mathbf{v}_1^\tau \\
            \vdots \\
            \mathbf{v}_t^\tau \\
        \end{pmatrix}
        \mathbf{\Sigma}_{YY}^{-1/2} \mathbf{\Sigma}_{YX}\mathbf{\Sigma}_{XX}^{-1} \\
        \mathbf{H}^{\left(t\right)} &amp; =
        \begin{pmatrix}
            \mathbf{v}_1^\tau \\
            \vdots \\
            \mathbf{v}_t^\tau \\
        \end{pmatrix}
        \mathbf{\Sigma}_{YY}^{-1/2} \\
    \end{aligned}
\end{equation}\]</span>
<p>where <span class="math inline">\(\mathbf{v}_j\)</span> is the eigenvector associated with the <span class="math inline">\(j\)</span>th largest eigenvalue of</p>
<span class="math display">\[\begin{equation}
    \begin{aligned}
        \mathbf{R} &amp; = \mathbf{\Sigma}_{YY}^{-1/2}\mathbf{\Sigma}_{YX} \mathbf{\Sigma}_{XX}^{-1} \mathbf{\Sigma}_{XY} \mathbf{\Sigma}_{YY}^{-1/2}
    \end{aligned}
\end{equation}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### COMBO-17 galaxy data
<span class="co">#data(COMBO17)</span>
<span class="co">#galaxy &lt;- as_data_frame(COMBO17) %&gt;%</span>
<span class="co">#       select(-starts_with("e."), -Nr, -UFS:-IFD) %&gt;%</span>
<span class="co">#       na.omit()</span>

<span class="co">#galaxy_x &lt;- galaxy %&gt;% select(-Rmag:-chi2red)</span>
<span class="co">#galaxy_y &lt;- galaxy %&gt;% select(Rmag:chi2red)</span>

<span class="co">#galaxy_x</span>
<span class="co">#galaxy_y</span></code></pre></div>
</div>
<div id="linear-discriminant-analysis" class="section level2">
<h2 class="hasAnchor"><html><body><a href="#linear-discriminant-analysis" class="anchor"> </a></body></html>Linear Discriminant Analysis</h2>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2>Contents</h2>
      <ul class="nav nav-pills nav-stacked"><li><a href="#principal-components-analysis">Principal Components Analysis</a></li>
      <li><a href="#canonical-variate-analysis">Canonical Variate Analysis</a></li>
      <li><a href="#linear-discriminant-analysis">Linear Discriminant Analysis</a></li>
      </ul></div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Chris Addy.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer></div>

  </body></html>
